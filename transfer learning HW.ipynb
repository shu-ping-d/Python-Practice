{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#載入套件及資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Layers for FNN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "# Layers for CNN\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, GlobalAveragePooling2D\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "# For data preprocessing\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#資料前處理\n",
    "#使用cifar10資料集(跟手寫資料大小不同)\n",
    "#原本28X28>>32X32\n",
    "# (#有cifar100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#類別名稱\n",
    "name_list = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR 10\n",
    "(X_train, y_train0), (X_test, y_test0) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize the range of featurs\n",
    "X_train = X_train / X_train.max()\n",
    "X_test = X_test / X_test.max()\n",
    "\n",
    "# One-hot encoding\n",
    "y_train = to_categorical(y_train0, 10)\n",
    "y_test = to_categorical(y_test0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.random.randint(X_train.shape[0])\n",
    "X_sample = X_train[idx]\n",
    "y_sample = y_train0[idx].squeeze()\n",
    "\n",
    "plt.imshow(X_sample)\n",
    "plt.title(name_list[y_sample])\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立用於分類 CIFAR 10 的卷積神經網路\n",
    "#透過不同方式 重複件模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shupi\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "#La-Net 5模型 3(2)卷基層+2(3)全連皆層\n",
    "model = Sequential()\n",
    "\n",
    "# First convolutional block\n",
    "## 2d捲基層+磁化層\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "# Second convolutional block\n",
    "## 2d捲基層+磁化層\n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "# Third convolutional block\n",
    "## 2d捲基層+磁化層\n",
    "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Fully-connected layers as a classfier\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "\n",
    "# Ouput layer: # of neurons = # of classes with softmax activation\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       36992     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 512)         590336    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 762,122\n",
      "Trainable params: 762,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#編譯模型: 設定模型訓練時的設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(),\n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#訓練模型: 透過訓練來學習分類資料的函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "50000/50000 [==============================] - 453s 9ms/sample - loss: 1.7717 - categorical_accuracy: 0.3319 - val_loss: 1.6205 - val_categorical_accuracy: 0.4029\n",
      "Epoch 2/3\n",
      "50000/50000 [==============================] - 448s 9ms/sample - loss: 1.4349 - categorical_accuracy: 0.4732 - val_loss: 1.4593 - val_categorical_accuracy: 0.4553\n",
      "Epoch 3/3\n",
      "50000/50000 [==============================] - 462s 9ms/sample - loss: 1.2634 - categorical_accuracy: 0.5409 - val_loss: 1.1761 - val_categorical_accuracy: 0.5798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x275c459c448>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, \n",
    "          batch_size=128, \n",
    "          epochs=3,\n",
    "          validation_data=(X_test, y_test)\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('LeNet5_CIFAR10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 151s 3ms/sample - loss: 1.1650 - categorical_accuracy: 0.5816 - los\n",
      "10000/10000 [==============================] - 31s 3ms/sample - loss: 1.1761 - categorical_accuracy: 0.5798s - l\n",
      "Train Accuracy: 58.160001039505005\n",
      "Test Accuracy: 57.9800009727478\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('LeNet5_CIFAR10.h5')\n",
    "\n",
    "score_train = model.evaluate(X_train, y_train)\n",
    "score_test = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f'Train Accuracy: {score_train[1]*100}')\n",
    "print(f'Test Accuracy: {score_test[1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x275c4162f88>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x275c4406fc8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x275c44b0848>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x275c44c4948>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x275c44d2208>,\n",
       " <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D at 0x275c449cf88>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x275c440a208>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x275c44bc708>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#另一種使用 Sequential 建立模型的方式\n",
    "#用list的方式\n",
    "CNN_layers = [Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu', name='Conv_1'),\n",
    "              MaxPool2D(),\n",
    "              Conv2D(128, (3, 3), padding='same', activation='relu', name='Conv_2'),\n",
    "              MaxPool2D(),\n",
    "              Conv2D(512, (3, 3), padding='same', activation='relu', name='Conv_3'),\n",
    "              GlobalAveragePooling2D()]\n",
    "\n",
    "FC_layers = [Dense(units=256, activation='relu'),\n",
    "             Dense(units=10, activation='softmax')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x275c43b4208>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x275c43b46c8>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x275c43b4748>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x275c43b4f08>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x275c43a20c8>,\n",
       " <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D at 0x275c43a28c8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x275c43b41c8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x275c43b8488>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_layers + FC_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       36992     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 512)         590336    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 762,122\n",
      "Trainable params: 762,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#跟下面的model比較\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 16, 16, 128)       36992     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "Conv_3 (Conv2D)              (None, 8, 8, 512)         590336    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 762,122\n",
      "Trainable params: 762,122\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2 = Sequential(CNN_layers+FC_layers)\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(loss='categorical_crossentropy', \n",
    "                optimizer=Adam(),\n",
    "                metrics=['categorical_accuracy'])\n",
    "\n",
    "model_2.load_weights('LeNet5_CIFAR10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 140s 3ms/sample - loss: 1.1650 - categorical_accuracy: 0.5816\n",
      "10000/10000 [==============================] - 28s 3ms/sample - loss: 1.1761 - categorical_accuracy: 0.5798\n",
      "Train Accuracy: 58.160001039505005\n",
      "Test Accuracy: 57.9800009727478\n"
     ]
    }
   ],
   "source": [
    "score_train = model_2.evaluate(X_train, y_train, batch_size=1024)\n",
    "score_test = model_2.evaluate(X_test, y_test, batch_size=1024)\n",
    "\n",
    "print(f'Train Accuracy: {score_train[1]*100}')\n",
    "print(f'Test Accuracy: {score_test[1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#遷移學習 (Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引進新的資料集 cifar100\n",
    "# \"種類\"數量不同\n",
    "(U_train, v_train0), (U_test, v_test0) = datasets.cifar100.load_data()\n",
    "\n",
    "# Normalize the range of featurs\n",
    "U_train = U_train / U_train.max()\n",
    "U_test = U_test / U_test.max()\n",
    "\n",
    "# One-hot encoding\n",
    "v_train = to_categorical(v_train0, 100)\n",
    "v_test = to_categorical(v_test0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "FC_layers_CF100 = [Dense(units=256, activation='relu'),\n",
    "                   Dense(units=128, activation='relu'),\n",
    "                   Dense(units=100, activation='softmax')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 16, 16, 128)       36992     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "Conv_3 (Conv2D)              (None, 8, 8, 512)         590336    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               12900     \n",
      "=================================================================\n",
      "Total params: 805,348\n",
      "Trainable params: 805,348\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_CF100 = Sequential(CNN_layers+FC_layers_CF100)\n",
    "model_CF100.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#訓練新模型\n",
    "#Fine-tune: 新資料集的樣本數夠多，整個模型重新訓練\n",
    "#Frozen: 當新資料集的樣本數不夠多，凍結借來的部分，只針對新建立的神經網路層訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in CNN_layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 174s 3ms/sample - loss: 3.8162 - categorical_accuracy: 0.1145 - val_loss: 3.4772 - val_categorical_accuracy: 0.1603\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 173s 3ms/sample - loss: 3.3472 - categorical_accuracy: 0.1874 - val_loss: 3.2825 - val_categorical_accuracy: 0.1994\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 3.1864 - categorical_accuracy: 0.2151 - val_loss: 3.1497 - val_categorical_accuracy: 0.2211\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 3.0838 - categorical_accuracy: 0.2369 - val_loss: 3.0613 - val_categorical_accuracy: 0.2476\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 171s 3ms/sample - loss: 3.0130 - categorical_accuracy: 0.2514 - val_loss: 2.9974 - val_categorical_accuracy: 0.2509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2764528d0c8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_CF100.compile(loss='categorical_crossentropy', \n",
    "                    optimizer=Adam(),\n",
    "                    metrics=['categorical_accuracy'])\n",
    "\n",
    "model_CF100.fit(U_train, v_train,\n",
    "                batch_size=128, \n",
    "                epochs=5,\n",
    "                validation_data=(U_test, v_test)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 148s 3ms/sample - loss: 1.1650 - categorical_accuracy: 0.5816\n",
      "10000/10000 [==============================] - 30s 3ms/sample - loss: 1.1761 - categorical_accuracy: 0.5798\n",
      "Train Accuracy: 58.160001039505005\n",
      "Test Accuracy: 57.9800009727478\n"
     ]
    }
   ],
   "source": [
    "score_train = model_2.evaluate(X_train, y_train)\n",
    "score_test = model_2.evaluate(X_test, y_test)\n",
    "\n",
    "print(f'Train Accuracy: {score_train[1]*100}')\n",
    "print(f'Test Accuracy: {score_test[1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
